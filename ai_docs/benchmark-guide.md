# Benchmark Guide - Zero-Allocation Performance

**Last Updated:** 2025-11-08  
**Status:** Ready to Execute  
**Branch:** copilot/implement-zero-alloc-structures

---

## Overview

This guide explains how to run and interpret performance benchmarks for the zero-allocation ETL implementation.

## Available Benchmarks

### 1. CsvExtractorBenchmark

Compares V1 (Dictionary-based) vs V2 (EtlRecord-based) CSV extraction performance.

**Location:** `tests/Benchmark/CsvExtractorBenchmark.cs`

**What it measures:**
- **V1_CsvExtractor_Dictionary** - Baseline (traditional approach with allocations)
- **V2_CsvExtractor_EtlRecord** - Optimized (zero-allocation approach)
- **Overhead_Dictionary_Creation** - Pure Dictionary overhead
- **Overhead_EtlRecord_Creation** - Pure EtlRecord overhead

**Parameters:**
- Row counts: 100, 1,000, 10,000
- 6 fields per row: Id, Name, Age, Salary, Active, Department
- Real CSV file parsing

### 2. ZeroAllocBenchmark

Basic structure-level benchmarks for FieldValue and EtlRecord operations.

**Location:** `tests/Benchmark/ZeroAllocBenchmark.cs`

**What it measures:**
- Traditional Dictionary allocation patterns
- Zero-allocation EtlRecord patterns
- Boxing/unboxing overhead
- FieldValue union type performance

## Running Benchmarks

### Quick Start

```bash
cd tests/Benchmark
dotnet run -c Release
```

### Run Specific Benchmark

```bash
cd tests/Benchmark
dotnet run -c Release --filter *CsvExtractorBenchmark*
```

### Run with Specific Parameters

```bash
cd tests/Benchmark
dotnet run -c Release --filter *CsvExtractorBenchmark.V2_CsvExtractor_EtlRecord*
```

### Advanced Options

```bash
# Longer runs for more accurate results
dotnet run -c Release --job Long

# Export results to multiple formats
dotnet run -c Release --exporters json,html,csv

# Memory profiler
dotnet run -c Release --profiler ETW
```

## Interpreting Results

### Key Metrics

**Mean (Average Time):**
- How long each operation takes on average
- Lower is better
- Compare V1 vs V2 to see improvement ratio

**Allocated Memory:**
- Total memory allocated per operation
- **This is the key metric for zero-allocation work**
- V2 should show dramatically less allocation than V1

**Gen0/Gen1/Gen2 Collections:**
- Garbage collection activity
- V2 should have significantly fewer collections
- Fewer collections = more consistent performance

### Expected Results

#### For CsvExtractorBenchmark:

**10,000 Rows:**

| Method | Mean | Allocated |
|--------|------|-----------|
| V1 (Dictionary) | ~50 ms | ~2.5 MB |
| V2 (EtlRecord) | ~25 ms | ~10 KB |

**Expected Improvements:**
- **Time:** 2x faster (50ms â†’ 25ms)
- **Allocations:** 99% reduction (2.5MB â†’ 10KB)
- **GC Collections:** ~40 Gen0 â†’ ~2 Gen0

#### For ZeroAllocBenchmark:

**10,000 Operations:**

| Method | Allocated per 10K ops |
|--------|----------------------|
| TraditionalDictionary | ~2.8 MB |
| ZeroAllocEtlRecord | ~512 bytes |
| TraditionalWithBoxing | ~320 KB |
| ZeroAllocFieldValue | ~0 bytes |

## Understanding BenchmarkDotNet Output

### Sample Output

```
| Method              | RowCount | Mean     | Allocated |
|-------------------- |--------- |---------:|----------:|
| V1_Dictionary       | 100      | 1.234 ms | 50.12 KB  |
| V2_EtlRecord        | 100      | 0.567 ms |  0.51 KB  |
| V1_Dictionary       | 10000    | 45.67 ms | 2.45 MB   |
| V2_EtlRecord        | 10000    | 18.23 ms | 9.87 KB   |
```

**Analysis:**
- V2 is ~2.5x faster (45.67ms â†’ 18.23ms for 10K rows)
- V2 allocates 99.6% less memory (2.45MB â†’ 9.87KB)
- Improvement scales with data size

### Red Flags

âš ï¸ **Warning Signs:**
- If V2 shows MORE allocations than V1
- If V2 is SLOWER than V1
- If GC collections are HIGHER in V2

**Troubleshooting:**
1. Ensure running in Release mode
2. Check buffer pooling is working
3. Verify no Debug.Assert or logging in hot path
4. Review stack traces for unexpected allocations

## Baseline Establishment

### Before Optimization

Run benchmarks on main branch to establish baseline:

```bash
git checkout main
cd tests/Benchmark
dotnet run -c Release --filter *CsvExtractorBenchmark* > baseline.txt
```

### After Optimization

Run benchmarks on feature branch:

```bash
git checkout copilot/implement-zero-alloc-structures
cd tests/Benchmark
dotnet run -c Release --filter *CsvExtractorBenchmark* > optimized.txt
```

### Compare

Use BenchmarkDotNet's comparison features:

```bash
dotnet run -c Release --filter *CsvExtractorBenchmark* --baseline baseline.txt
```

## CI/CD Integration

### GitHub Actions

Add to `.github/workflows/benchmark.yml`:

```yaml
name: Benchmarks

on:
  pull_request:
    branches: [ main ]
  workflow_dispatch:

jobs:
  benchmark:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Setup .NET
        uses: actions/setup-dotnet@v3
        with:
          dotnet-version: '8.0.x'
      - name: Run Benchmarks
        run: |
          cd tests/Benchmark
          dotnet run -c Release --exporters json
      - name: Upload Results
        uses: actions/upload-artifact@v3
        with:
          name: benchmark-results
          path: tests/Benchmark/BenchmarkDotNet.Artifacts/
```

## Performance Goals

### Phase 3 Targets

**CSV Extraction (10K rows):**
- âœ… Allocations: < 50 KB (vs ~2.5 MB baseline) - **95%+ reduction**
- âœ… Throughput: > 400K rows/sec (vs ~200K baseline) - **2x improvement**
- âœ… GC Time: < 2ms (vs ~20ms baseline) - **90% reduction**

**FieldValue Operations (1M ops):**
- âœ… Zero boxing for primitives
- âœ… < 1KB total allocations
- âœ… No GC pressure

**EtlRecord Operations (1M ops):**
- âœ… Stack-only allocation
- âœ… Reused buffers
- âœ… < 10KB total allocations

## Troubleshooting

### Benchmark Fails to Run

**Issue:** `Could not load file or assembly`
**Solution:** 
```bash
cd tests/Benchmark
dotnet clean
dotnet build -c Release
dotnet run -c Release
```

### Unexpected Allocations

**Issue:** V2 shows allocations where none expected
**Solution:**
1. Use memory profiler: `--profiler ETW`
2. Check for string allocations
3. Review ToString() calls
4. Verify buffer pooling

### Inconsistent Results

**Issue:** Benchmark results vary significantly
**Solution:**
1. Close other applications
2. Run longer: `--job Long`
3. Run multiple times: `--launchCount 5`
4. Check for thermal throttling

## Next Steps

After running benchmarks:

1. **Document Results** - Add actual numbers to PR description
2. **Compare Against Goals** - Verify targets are met
3. **Identify Bottlenecks** - Use profiler if goals not met
4. **Iterate** - Optimize hot paths if needed
5. **Celebrate** - If goals exceeded! ðŸŽ‰

## References

- [BenchmarkDotNet Documentation](https://benchmarkdotnet.org/)
- [Memory Diagnostics Guide](https://benchmarkdotnet.org/articles/configs/diagnosers.html)
- [.NET Performance Best Practices](https://learn.microsoft.com/en-us/dotnet/framework/performance/)

---

**Author:** GitHub Copilot AI Agent  
**Reviewers:** Pending  
**Version:** 1.0
